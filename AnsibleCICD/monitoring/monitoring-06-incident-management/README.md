# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 

> Составьте постмортем, на основе реального сбоя системы Github в 2018 году.
> 
> Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
> также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).


`Постмортем` является “ревью” на произошедший инцидент информационной системы.

### План Постмортем
1. Краткое описание инцидента.
2. Предшествующие события.
3. Причина инцидента.
4. Воздействие. (На что повлиял инцидент)
5. Обнаружение. (Когда и как инцидент был обнаружен)
6. Реакция. (Кто ответил на инцидент, кто был привлечен, какие каналы коммуникации были задействованы)
7. Восстановление. (Описание действий по устранению инцидента и поведение системы)
8. Таймлайн. (Последовательное описание ключевых событий инцидента с указанием времени)
9. Последующие действия. (Что нужно предпринять, чтобы инцидент не повторялся)

#### 1. Краткое описание инцидента.
После непродолжительной потери связи между сетевым узлом и датацентром нарушилась топология кластеров Оркестратора, что привело к деградированию системы.

#### 2. Предшествующие события.
Плановые работы по техническому обслуживанию для замены вышедшего из строя оптического оборудования 100G на Восточном побережье США.

#### 3. Причина инцидента.
Потеря связи между сетевым узлом и основным центром обработки данных. В результате кластеры MySQL перешли в состояни`unexpected` (неожиданное) для Оркестратора.

#### 4. Воздействие.
Отображение устаревшей и непоследовательной информации. Не функционировали WebHook, сборка, публикация GitHub Pages.

#### 5. Обнаружение.
Инцидент был замечен дежурными инженерами через оповещения системы мониторинга.

#### 6. Реакция.
Группа реагирования отключила часть сервисов для минимизации изменений БД. 
Далее к работе подключились координатор и дополнительные разработчики из инженерной группы БД.
Время восстановления составило 24 часа 11 минут.

#### 7. Восстановление.
Временно отключили часть сервисов для мининизации накопления изменений.
После чего восстановили данные из резервных копий, а на них реплицировали накопленные.
Далее вручную переконфигурировали топологию кластеров БД и включили деактивированный функционал.
В конце дождались отработки накопленных задач. Для этого развернуть дополнительные временные реплики на чтение.

#### 8. Таймлайн.
`21 октября 2018, 22:52 UTC` - Нарушилась связь между сетевым узлом и основным дата-центром на восточном побережье США

`21 октября 2018, 22:52 UTC` - Оркестратор в основном дата-центре запустил процесс выбора нового лидера, в результате чего начал создавать топологию кластера БД на западе. 
После восстановления подключения приложения направили трафик по записи на новые основные сервера на западе. 
Таким образом на обоих серверах образовались данные, отсутствующие у другого и не получилось вернуть первичный сервер не восток.

`21 октября 2018, 22:54 UTC` - Внутренние системы мониторинга начали генерировать оповещения о многочисленных сбоях в работе систем.

`21 октября 2018, 23:02 UTC` - Инженеры первой группы реагирования определили, что топологии для многочисленных кластеров БД находятся в неожиданном состоянии - 
при запросе API Оркестратора отображалась топология репликации БД, содержащая только серверы из западного ЦОД.

`21 октября 2018, 23:07 UTC` - Группа реагирования вручную заблокировала внутренние средства развёртывания, чтобы предотвратить внесение дополнительных изменений в БД.

`21 октября 2018, 23:09 UTC` - Группа реагирования установила жёлтый статус работоспособности сайта (статус активного инцидента).

`21 октября 2018, 23:11 UTC` - Координатор присоединился к работе и через две минуты принял решение изменить статус сайта на красный.

`21 октября 2018, 23:13 UTC` - К работе привлекли дополнительных разработчиков из инженерной группы БД, 
которые начали исследовать текущее состояние для определения необходимых действий для ручной перенастроийки БД.

`21 октября 2018, 23:19 UTC` - В целях сохранности данных принято решение об остановке выполнения заданий, которые пишут метаданные типа пуш-запросов.

`22 октября 2018, 00:05 UTC` - Инженеры из группы реагирования начали разрабатывать план устранения несогласованности данных и запустили процедуры отработки отказа для MySQL.

`22 октября 2018, 00:41 UTC` - Инициирован процесс резервного копирования для всех затронутых кластеров MySQL. 
Одновременно нескольок групп инженеров изучали способы ускорения передачи и восстановления без дальнейшей деградации сайта или риска повреждения данных.

`22 октября 2018, 06:51 UTC` - Несколько кластеров на востоке завершили восстановление из резервных копий и начали реплицировать новые данные с Западным побережьем.

`22 октября 2018, 07:46 UTC` - Публикация информационного сообщение об инциденте.

`22 октября 2018, 11:12 UTC` - Все первичные БД вновь переведены на Восток, но не смотря на возросшую производительность сайта некоторые данные всё ещё отставали 
на несколько часов из-за отложенных реплик.

`22 октября 2018, 13:15 UTC` - Зафиксировано возрастание отставания репликации до согласованного состояния (время увеличивалось, а не уменьшалось). 
Начали подготовку дополнительных реплик чтения MySQL в общедоступном облаке Восточного побережья.

`22 октября 2018, 16:24 UTC` - Завершена синхронизация реплик - возврат к исходной топологии. Устранинены проблемы задержки и доступности. 
Однако, красный статус сохранён, так как нужно ещё обработать накопленные данные.

`22 октяюря 2018, 16:45 UTC` - Включение всех дэактивированных функций. Корректировка TTL более 200000 истекших за время восстановления задач из более 5 миллионов.

`22 октября 2018, 23:03 UTC` - Все незавершённые события webhook и сборки Pages обработаны, а целостность и правильная работа всех систем подтверждена. 
Статус сайта изменён на зелёный

#### 9. Последующие действия.
Ввели chaos engineering. Начали систематическую практику проверки сценариев сбоев.
